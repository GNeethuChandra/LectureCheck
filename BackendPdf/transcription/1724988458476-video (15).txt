Good morning everyone. This is Neetu Chandra from Lecture Tech. I'm very excited to share with you an innovative project we have been working on. Let's look at our problem statement. Our system is designed to assist professors in uploading their videos along with their corresponding PDF's and performing thorough content analysis. This analysis not only validates the lectures for topic wise coverage, but also ensures the video content aligns accurately with the PDF materials provided. Using advanced technologies like large language models for audio to text conversion and sophisticated algorithms for content analysis, our system promises to elevate the quality and effectiveness of educational content provided by delivered by professors. In this presentation now we'll highlight the key features of our project, demonstrate the functionality, and discuss the cutting edge technology behind it. These are the objectives of our project. Our system facilitates lecture uploading, matching video content with PDF's, and visualization of results in the form of graphs and percentages. This is the technical stack of our project. We use Mon for its powerful combination of technologies for that cover both front end and backend, MongoDB for data management, Express J's for flexible and scalable server side applications and react J's for user friendly and responsive interface node J's for executing the server side logic and asynchronous operations. Additionally, we use LLM for. We use large language models for to enhance our systems capabilities. These models these models enhance advanced text processing and content analysis, providing valuable insights and improving overall functionality. This is the architecture of our project. Users, in our case, users are processors and the front end powered by React provides a user friendly interface for the professors node. Js and Expressjs work together to handle API request, manage data flow and execute server side logic efficiently. And MongoDB serves as data store of our project to maintain large volumes of data and additionally we incorporate LLMdez to that enable advanced text processing and content analysis. This is the workflow of our project. First of all, lectures upload a video. Once the video is uploaded, it gets converted to audio. I mean audio is extracted from the video and a text and once the video audio is extracted, then it gets converted into text. For extracting audio we are using a note package called MPEG and for transcription we are using LLM model called Wishbar. Once it's done, the PDF is uploaded. Once the PDF is uploaded, it is it gets converted to text. For extracting text from PDF, you're using a note package called Parse PDF. The text extracted from PDF and the transcription from video. Both of them are given to the LLM for similarity check. Once the similarity score is generated, it gets displayed in the front end. Thank you. Now let's look at the actual demo of our project. This is the login page. As there are no videos uploaded, it's showing more uploads available. Download me upload a video cv was successfully uploaded here and we can see the video here. Then next when we click on next, this PF page will be available see PDF section. You can also view it here. So see this is the lecture check one that PDF only and you have already seen the video which I have uploaded. It is the same lecture check media only. So if the similarity score is working well then it should give approximately zero point above score for this as both of them matches a lot because both of them are related to the project only. Let's see, when I click on next it will show the similarity score. See it's about 0.5. That is 0.85. That means most of it matches. So this is the project and there is still little UI part is left. Be doing it soon. Thank you so much for being here. Look forward to share our progress with you. Thank you.